# ğŸš€ Projet Big Data - PrÃ©diction des Retards de Vols

## Architecture Big Data ComplÃ¨te avec Docker

[![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)](https://www.docker.com/)
[![Apache Spark](https://img.shields.io/badge/Apache%20Spark-E25A1C?style=for-the-badge&logo=apachespark&logoColor=white)](https://spark.apache.org/)
[![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-231F20?style=for-the-badge&logo=apachekafka&logoColor=white)](https://kafka.apache.org/)
[![Cassandra](https://img.shields.io/badge/Cassandra-1287B1?style=for-the-badge&logo=apachecassandra&logoColor=white)](https://cassandra.apache.org/)
[![Hadoop](https://img.shields.io/badge/Hadoop-66CCFF?style=for-the-badge&logo=apachehadoop&logoColor=black)](https://hadoop.apache.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)](https://streamlit.io/)

Ce projet implÃ©mente une **Architecture Lambda** complÃ¨te et professionnelle pour l'analyse en temps rÃ©el et historique des retards de vols en utilisant l'Ã©cosystÃ¨me Big Data moderne, orchestrÃ© avec Docker Compose.

---

## ğŸ“‹ Table des MatiÃ¨res

1. [ğŸ¯ Vue d'ensemble](#-vue-densemble)
2. [ğŸ—ï¸ Architecture](#ï¸-architecture)
3. [ğŸ’» Technologies](#-technologies)
4. [ğŸ“¦ PrÃ©requis](#-prÃ©requis)
5. [ğŸš€ Installation Rapide](#-installation-rapide)
6. [âš™ï¸ Configuration](#ï¸-configuration)
7. [ğŸ® Utilisation](#-utilisation)
8. [ğŸ“Š Dashboard Streamlit](#-dashboard-streamlit)
9. [ğŸ“ Structure du Projet](#-structure-du-projet)
10. [ğŸ› ï¸ Commandes Utiles](#ï¸-commandes-utiles)
11. [ğŸ› DÃ©pannage](#-dÃ©pannage)
12. [ğŸ“ˆ RÃ©sultats](#-rÃ©sultats)
13. [ğŸ¤ Contribution](#-contribution)
14. [ğŸ“ Licence](#-licence)

---

## ğŸ¯ Vue d'ensemble

### ğŸ“Š Objectif du Projet

Ce projet implÃ©mente une **Architecture Lambda** complÃ¨te pour l'analyse et le monitoring des retards de vols des compagnies aÃ©riennes amÃ©ricaines. Il combine traitement batch historique et streaming temps rÃ©el pour fournir une vue unifiÃ©e des donnÃ©es.

### âœ¨ FonctionnalitÃ©s Principales

- âœ… **Traitement Batch** : Analyse de 7.2+ millions de vols historiques avec Apache Spark
- âœ… **Traitement Streaming** : Ingestion temps rÃ©el via Kafka et traitement avec Python
- âœ… **Stockage Hybride** : HDFS pour donnÃ©es historiques, Cassandra pour temps rÃ©el
- âœ… **Dashboard Interactif** : Visualisation Streamlit avec graphiques Plotly
- âœ… **Architecture Scalable** : Infrastructure containerisÃ©e avec Docker Compose
- âœ… **Monitoring** : Interfaces web pour tous les composants (Spark UI, HDFS UI, etc.)

### ğŸ“Š Dataset

- **Source**: [Kaggle - Airline Delay and Cancellation Data (2009-2018)](https://www.kaggle.com/datasets/yuanyuwendymu/airline-delay-and-cancellation-data-2009-2018)
- **Taille**: 892 MB (fichier 2018.csv utilisÃ©)
- **Enregistrements**: 7,213,446 vols
- **AÃ©roports**: 358 aÃ©roports uniques
- **Colonnes**: 28 attributs incluant retards d'arrivÃ©e/dÃ©part, distances, compagnies, etc.

### ğŸ¯ Cas d'Usage

1. **Analyse Historique** : Identifier les aÃ©roports avec retards chroniques
2. **Monitoring Temps RÃ©el** : Suivre les retards actuels aÃ©roport par aÃ©roport
3. **Comparaison** : DÃ©tecter les anomalies en comparant historique vs temps rÃ©el
4. **PrÃ©diction** : Base pour modÃ¨les ML de prÃ©diction de retards

---

## ğŸ—ï¸ Architecture

### Diagramme d'Architecture Lambda

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ARCHITECTURE LAMBDA                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   Dataset    â”‚
                        â”‚ Flights 2018 â”‚
                        â”‚   (892 MB)   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”»â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
                â–¼                              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    BATCH LAYER        â”‚      â”‚    SPEED LAYER        â”‚
    â”‚  (DonnÃ©es historiques)â”‚      â”‚  (DonnÃ©es temps rÃ©el) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                              â”‚
                â”‚  1. HDFS Upload              â”‚  1. Kafka Producer
                â”‚     (9870)                   â”‚     (9092)
                â–¼                              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Hadoop HDFS          â”‚      â”‚  Apache Kafka         â”‚
    â”‚  /data/flights_raw/   â”‚      â”‚  Topic: live-flights  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                              â”‚
            â”‚  2. Spark Batch Job          â”‚  2. Python Consumer
            â”‚     (8080, 7077)             â”‚     + Aggregation
            â–¼                              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Apache Spark         â”‚      â”‚  Apache Cassandra     â”‚
    â”‚  - 7.2M vols analysÃ©s â”‚      â”‚  realtime.recent_delaysâ”‚
    â”‚  - 358 aÃ©roports      â”‚      â”‚  - Updates temps rÃ©el â”‚
    â”‚  - AgrÃ©gations        â”‚      â”‚  - 30s refresh        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                              â”‚
            â”‚  3. Sauvegarde Hive          â”‚
            â”‚     (10000)                  â”‚
            â–¼                              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
    â”‚  Apache Hive          â”‚              â”‚
    â”‚  batch_views.         â”‚              â”‚
    â”‚  airport_delay_stats  â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
            â”‚                              â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚    SERVING LAYER         â”‚
            â”‚  (RequÃªtes unifiÃ©es)     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â”‚  Dashboard Streamlit (8501)
                       â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  ğŸ“Š VISUALISATION        â”‚
            â”‚  - Vue d'ensemble        â”‚
            â”‚  - Recherche aÃ©roport    â”‚
            â”‚  - Batch vs Speed        â”‚
            â”‚  - Auto-refresh          â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”„ Flux de DonnÃ©es

#### Batch Layer (Traitement Historique)
1. **Ingestion** : Fichier CSV 2018.csv uploadÃ© dans HDFS
2. **Traitement** : Job Spark lit HDFS, agrÃ¨ge par aÃ©roport
3. **Stockage** : RÃ©sultats sauvegardÃ©s dans Hive
4. **RÃ©sultat** : 358 aÃ©roports avec statistiques complÃ¨tes

#### Speed Layer (Traitement Temps RÃ©el)
1. **Ingestion** : Producer Kafka lit CSV et envoie messages
2. **Streaming** : Consumer Python lit Kafka en continu
3. **AgrÃ©gation** : Calcul des moyennes par batch de 100 messages
4. **Stockage** : Ã‰criture dans Cassandra table `recent_delays`

#### Serving Layer (Unification)
1. **Lecture** : Dashboard interroge Hive (batch) et Cassandra (speed)
2. **Fusion** : Combinaison des deux sources de donnÃ©es
3. **Visualisation** : Graphiques interactifs avec Plotly
4. **Refresh** : Mise Ã  jour automatique toutes les 30 secondes

---

## ï¿½ Technologies

### Stack Technique ComplÃ¨te

| Composant | Technologie | Version | RÃ´le | Port(s) |
|-----------|-------------|---------|------|---------|
| **Stockage DistribuÃ©** | Apache Hadoop HDFS | 3.1.1 | Stockage fichiers distribuÃ© | 9870 (UI), 9000 (RPC) |
| **Traitement Batch** | Apache Spark | 3.3.0 | Calculs distribuÃ©s massifs | 8080 (UI), 7077 (Master) |
| **Message Streaming** | Apache Kafka | 7.0.1 | File de messages pub/sub | 9092, 29092 |
| **Coordination** | Apache Zookeeper | 7.0.1 | Coordination Kafka | 2181 |
| **Base NoSQL** | Apache Cassandra | 4.0 | Stockage temps rÃ©el | 9042 (CQL) |
| **Data Warehouse** | Apache Hive | 2.3.2 | SQL sur Hadoop | 10000 (HiveServer2) |
| **Dashboard** | Streamlit | 1.50.0 | Interface web interactive | 8501 |
| **Visualisation** | Plotly | 6.3.1 | Graphiques interactifs | - |
| **Scripting** | Python | 3.9 | Jobs ETL et consumer | - |
| **Orchestration** | Docker Compose | 3 | Conteneurisation | - |

### ğŸ“¦ BibliothÃ¨ques Python

```python
# Core Data Processing
pandas==2.3.3
numpy==2.0.2

# Streaming & Database
kafka-python==2.2.15
cassandra-driver==3.29.3

# Visualization
streamlit==1.50.0
plotly==6.3.1
matplotlib==3.9.4

# Spark (installÃ© dans conteneur Spark)
pyspark==3.3.0
```

---

## ï¿½ PrÃ©requis

### ğŸ’» SystÃ¨me HÃ´te

| Composant | Minimum | RecommandÃ© |
|-----------|---------|------------|
| **RAM** | 16 GB | 32 GB |
| **CPU** | 4 cÅ“urs | 8 cÅ“urs |
| **Disque** | 50 GB libre | 100 GB libre |
| **OS** | Windows 10, macOS 10.15, Ubuntu 20.04 | Windows 11, macOS 13+, Ubuntu 22.04 |

### ğŸ› ï¸ Logiciels Requis

1. **Docker Desktop** (version 20.10+)
   - Windows: [TÃ©lÃ©charger](https://www.docker.com/products/docker-desktop/)
   - macOS: [TÃ©lÃ©charger](https://www.docker.com/products/docker-desktop/)
   - Linux: [Instructions d'installation](https://docs.docker.com/engine/install/)

2. **Docker Compose** (version 3+)
   - Inclus avec Docker Desktop sur Windows/Mac
   - Linux: Installation sÃ©parÃ©e requise

3. **Git** (pour cloner le repository)
   ```bash
   git --version  # VÃ©rifier l'installation
   ```

### âš™ï¸ Configuration Docker

**Allouer des ressources suffisantes Ã  Docker Desktop:**

1. Ouvrir **Docker Desktop** â†’ **Settings** â†’ **Resources**
2. Configurer:
   - **CPUs**: 4-6 cÅ“urs
   - **Memory**: 8-12 GB
   - **Swap**: 2 GB
   - **Disk image size**: 50 GB

---

## ğŸš€ Installation Rapide

### Ã‰tape 1: Cloner le Repository

```bash
git clone https://github.com/MayssenBHA/Mini_Project_Big_Data.git
cd Mini_Project_Big_Data
```

### Ã‰tape 2: PrÃ©parer le Dataset

1. **TÃ©lÃ©charger le dataset** depuis [Kaggle](https://www.kaggle.com/datasets/yuanyuwendymu/airline-delay-and-cancellation-data-2009-2018)
2. **Extraire** le fichier `2018.csv`
3. **Placer** dans le dossier `data/`:
   ```
   Mini_Project_Big_Data/
   â”œâ”€â”€ data/
   â”‚   â””â”€â”€ 2018.csv  â† Ici (892 MB)
   ```

### Ã‰tape 3: DÃ©marrer l'Infrastructure

```powershell
# DÃ©marrer tous les services Docker
docker compose up -d

# VÃ©rifier que tous les conteneurs sont actifs
docker compose ps
```

**Temps de dÃ©marrage**: ~2-3 minutes pour tous les services

### Ã‰tape 4: Initialiser les Composants

#### 4.1 Initialiser HDFS
```powershell
docker exec hadoop-master bash /scripts/init_hdfs.sh
```

#### 4.2 Initialiser Kafka
```powershell
docker exec kafka bash /scripts/init_kafka.sh
```

#### 4.3 Initialiser Cassandra
```powershell
docker exec cassandra bash /scripts/init_cassandra.sh
```

#### 4.4 Installer les dÃ©pendances Python
```powershell
docker exec python-env pip install -r /scripts/requirements.txt
```

### Ã‰tape 5: VÃ©rification

```powershell
# VÃ©rifier HDFS
docker exec hadoop-master hdfs dfs -ls /data/flights_raw/

# VÃ©rifier Kafka
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092

# VÃ©rifier Cassandra
docker exec cassandra cqlsh -e "DESCRIBE KEYSPACES;"
```

âœ… **Installation terminÃ©e !** Passez Ã  la section [Utilisation](#-utilisation)

---

## âš™ï¸ Configuration

### ğŸ”§ Configuration Hadoop (`configs/hadoop.env`)

```properties
CORE_CONF_fs_defaultFS=hdfs://hadoop-master:9000
CORE_CONF_hadoop_http_staticuser_user=root
HDFS_CONF_dfs_replication=3
HDFS_CONF_dfs_permissions_enabled=false
```

### ğŸ”§ Configuration Kafka

```yaml
KAFKA_BROKER_ID=1
KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
KAFKA_AUTO_CREATE_TOPICS_ENABLE=true
KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
```

### ğŸ”§ Configuration Cassandra

**Keyspace**: `realtime`  
**Replication**: SimpleStrategy (factor=1)

```sql
CREATE KEYSPACE IF NOT EXISTS realtime 
WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1};

CREATE TABLE IF NOT EXISTS realtime.recent_delays (
    origin TEXT PRIMARY KEY,
    recent_delay DOUBLE,
    recent_dep_delay DOUBLE
);
```

### ğŸ”§ Configuration Hive

**Database**: `batch_views`  
**Table**: `airport_delay_stats`

```sql
CREATE DATABASE IF NOT EXISTS batch_views;

CREATE TABLE IF NOT EXISTS batch_views.airport_delay_stats (
    origin STRING,
    avg_delay DOUBLE,
    avg_dep_delay DOUBLE,
    total_flights BIGINT,
    delayed_flights BIGINT,
    avg_distance DOUBLE,
    avg_air_time DOUBLE,
    delay_rate DOUBLE
) STORED AS PARQUET;
```

---

## ğŸ® Utilisation

### ğŸš€ Lancement Automatique (RecommandÃ©)

#### Option 1: Pipeline Complet
```powershell
.\run_full_pipeline.ps1
```

Cette commande lance automatiquement:
1. âœ… Batch Layer (Spark)
2. âœ… Speed Layer (Kafka + Consumer)
3. âœ… Dashboard Streamlit

#### Option 2: Scripts Individuels

**Lancer le Batch Layer:**
```powershell
.\launch_pipeline.ps1
```

**Lancer le Dashboard:**
```powershell
.\launch_dashboard.ps1
```

### ğŸ“‹ Lancement Manuel (Ã‰tape par Ã‰tape)

#### 1ï¸âƒ£ BATCH LAYER - Traitement Historique

```powershell
# Lancer le job Spark Batch
docker exec spark-master /spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  --deploy-mode client \
  --executor-memory 2G \
  --total-executor-cores 2 \
  /scripts/batch_job.py
```

**RÃ©sultat attendu:**
```
âœ“ 7,213,446 lignes chargÃ©es
âœ“ 7,076,406 lignes aprÃ¨s nettoyage
âœ“ Statistiques calculÃ©es pour 358 aÃ©roports
âœ“ DonnÃ©es sauvegardÃ©es dans batch_views.airport_delay_stats
```

**Top 5 aÃ©roports avec retards:**
- YNG: 75.0 min
- PPG: 47.9 min
- MMH: 35.6 min
- OTH: 26.0 min
- HYA: 26.0 min

#### 2ï¸âƒ£ SPEED LAYER - Traitement Temps RÃ©el

**DÃ©marrer le Producer Kafka:**
```powershell
Start-Job -ScriptBlock { 
    docker exec python-env python /scripts/producer_flights.py 
} -Name "KafkaProducer"
```

**DÃ©marrer le Consumer (Kafka â†’ Cassandra):**
```powershell
Start-Job -ScriptBlock { 
    docker exec python-env python /scripts/kafka_to_cassandra.py 
} -Name "KafkaConsumer"
```

**Surveiller les logs:**
```powershell
# Voir logs Producer
Receive-Job -Name "KafkaProducer" | Select-Object -Last 20

# Voir logs Consumer
Receive-Job -Name "KafkaConsumer" | Select-Object -Last 20
```

**VÃ©rifier les donnÃ©es dans Cassandra:**
```powershell
docker exec cassandra cqlsh -e "SELECT * FROM realtime.recent_delays LIMIT 10;"
```

#### 3ï¸âƒ£ SERVING LAYER - Dashboard

**Lancer Streamlit:**
```powershell
Start-Job -ScriptBlock { 
    docker exec python-env streamlit run /scripts/dashboard.py \
        --server.port 8501 \
        --server.address 0.0.0.0 \
        --server.headless true 
} -Name "StreamlitDashboard"
```

**AccÃ©der au dashboard:**
ğŸ‘‰ **http://localhost:8501**

---

## ğŸ“Š Dashboard Streamlit

### ğŸ¨ FonctionnalitÃ©s

Le dashboard offre **3 modes de visualisation** interactifs:

#### 1. ğŸ“Š Vue d'Ensemble

**Affichage:**
- Badges des 3 couches (Batch, Speed, Serving)
- MÃ©triques clÃ©s (nombre d'aÃ©roports, vols, retard moyen)
- Top 20 aÃ©roports Batch Layer (graphique en barres)
- Top 20 aÃ©roports Speed Layer (graphique en barres)
- Tableaux de donnÃ©es avec dÃ©gradÃ©s de couleur

**Utilisation:**
- Visualiser rapidement les aÃ©roports problÃ©matiques
- Comparer vue historique vs temps rÃ©el
- Identifier les tendances globales

#### 2. ğŸ” Recherche par AÃ©roport

**Affichage:**
- SÃ©lecteur d'aÃ©roport (dropdown)
- Graphique comparatif Batch vs Speed
- MÃ©triques dÃ©taillÃ©es (retards arrivÃ©e/dÃ©part)
- Code IATA de l'aÃ©roport

**Utilisation:**
```
1. SÃ©lectionner un aÃ©roport dans le menu dÃ©roulant
2. Voir la comparaison historique vs temps rÃ©el
3. Analyser les Ã©carts de retards
```

**AÃ©roports disponibles:** 358 codes IATA (ATL, DFW, ORD, LAX, etc.)

#### 3. ğŸ“ˆ Comparaison Batch vs Speed

**Affichage:**
- Scatter plot : Retards historiques vs temps rÃ©el
- Ligne de rÃ©fÃ©rence (y=x)
- Top 10 augmentations de retards
- Top 10 diminutions de retards
- Coefficient de corrÃ©lation

**InterprÃ©tation:**
- Points sur la ligne: Comportement stable
- Points au-dessus: Retards augmentÃ©s en temps rÃ©el
- Points en-dessous: Retards diminuÃ©s en temps rÃ©el

### âš™ï¸ Options du Dashboard

**Auto-Refresh:**
- â˜ DÃ©sactivÃ©: DonnÃ©es statiques
- â˜‘ï¸ ActivÃ©: RafraÃ®chissement automatique toutes les 30 secondes

**Cache:**
- Batch Layer: Cache 5 minutes
- Speed Layer: Cache 30 secondes

### ğŸ“¸ Captures d'Ã‰cran

#### Vue d'ensemble
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  âœˆï¸ Lambda Architecture Dashboard               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ—„ï¸ Batch  |  âš¡ Speed  |  ğŸ“Š Serving          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“Š 358 aÃ©roports | 7.2M vols | 12.5 min retard â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [Graphique Top 20 Batch]                       â”‚
â”‚  [Graphique Top 20 Speed]                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”— AccÃ¨s aux Interfaces Web

| Service | URL | Description |
|---------|-----|-------------|
| **Dashboard Streamlit** | http://localhost:8501 | Visualisation principale |
| **Spark Master UI** | http://localhost:8080 | Monitoring Spark jobs |
| **HDFS NameNode UI** | http://localhost:9870 | Exploration HDFS |
| **Kafka** | localhost:29092 | Connexion externe Kafka |

---

### Logiciels
- **Docker Desktop** (derniÃ¨re version)
  - Windows/Mac: [TÃ©lÃ©charger ici](https://www.docker.com/products/docker-desktop)
  - Linux: Docker Engine + Docker Compose
- **Git** (pour cloner le projet)

### VÃ©rification
```powershell
# VÃ©rifier Docker
docker --version
docker compose version

# VÃ©rifier les ressources Docker Desktop
# Ouvrir Docker Desktop â†’ Settings â†’ Resources
# Allouer au moins 8 GB RAM et 4 CPU cores
```

---

## ğŸ“¥ Installation

### Ã‰tape 1: Cloner ou CrÃ©er le Projet
```powershell
# Si le projet existe dÃ©jÃ 
cd C:\Users\mayssen\bigdata-project

# Sinon, crÃ©er la structure
mkdir bigdata-project
cd bigdata-project
mkdir data, scripts, configs, configs\hive
```

### Ã‰tape 2: TÃ©lÃ©charger le Dataset
1. Allez sur [Kaggle](https://www.kaggle.com/datasets/yuanyuwendymu/airline-delay-and-cancellation-data-2009-2018)
2. TÃ©lÃ©chargez le ZIP (~5 GB)
3. Extrayez les fichiers CSV dans `data/`
4. Pour tests, utilisez `2018.csv` (~7M lignes)

```powershell
# VÃ©rifier que les donnÃ©es sont prÃ©sentes
dir data\*.csv
```

### Ã‰tape 3: Lancer l'Infrastructure
```powershell
# Lancer tous les conteneurs
docker compose up -d

# VÃ©rifier que tous les services sont dÃ©marrÃ©s (peut prendre 2-5 minutes)
docker compose ps

# Vous devriez voir 8 conteneurs: hadoop-master, hadoop-datanode, 
# spark-master, spark-worker, kafka, zookeeper, cassandra, hive, python-env
```

### Ã‰tape 4: Attendre l'Initialisation
```powershell
# Attendre que tous les services soient prÃªts (2-5 minutes)
# VÃ©rifier les logs
docker compose logs -f
# Appuyer sur Ctrl+C pour sortir

# VÃ©rifier les interfaces web
# HDFS: http://localhost:9870
# Spark: http://localhost:8080
```

---

## âš™ï¸ Configuration

### 1. Initialiser HDFS
```powershell
# Charger les donnÃ©es dans HDFS
docker exec -it hadoop-master bash
/scripts/init_hdfs.sh
exit
```

### 2. Initialiser Kafka
```powershell
# CrÃ©er le topic Kafka
docker exec -it kafka bash
/scripts/init_kafka.sh
exit
```

### 3. Initialiser Cassandra
```powershell
# CrÃ©er le keyspace et la table
docker exec -it cassandra bash
/scripts/init_cassandra.sh
exit
```

### 4. Initialiser Hive
```powershell
# CrÃ©er la base de donnÃ©es
docker exec -it hive bash
/scripts/init_hive.sh
exit
```

### 5. Installer les DÃ©pendances Python
```powershell
# Installer kafka-python, pandas, etc.
docker exec -it python-env python /scripts/install_dependencies.py
```

---

## ğŸ® Utilisation

### Flux Complet End-to-End

#### 1ï¸âƒ£ Batch Layer (Traitement Historique)
```powershell
# Soumettre le job batch Spark
docker exec -it spark-master spark-submit `
  --master spark://spark-master:7077 `
  --deploy-mode client `
  /scripts/batch_job.py

# VÃ©rifier les rÃ©sultats dans Hive
docker exec -it hive beeline -u jdbc:hive2://localhost:10000
# Dans Beeline:
> SHOW DATABASES;
> USE batch_views;
> SHOW TABLES;
> SELECT * FROM airport_delay_stats ORDER BY avg_delay DESC LIMIT 10;
> !quit
```

#### 2ï¸âƒ£ Speed Layer (Streaming Temps RÃ©el)

**Ã‰tape 1: Lancer le Producer Kafka**
```powershell
# IngÃ©rer les donnÃ©es vers Kafka en arriÃ¨re-plan
Start-Job -ScriptBlock { 
    docker exec python-env python /scripts/producer_flights.py 
} -Name "KafkaProducer"

# VÃ©rifier les logs du producer
Receive-Job -Name "KafkaProducer" | Select-Object -Last 20
```

**Ã‰tape 2: Lancer le Consumer Kafka â†’ Cassandra**
```powershell
# Lancer le consumer Python qui lit Kafka et Ã©crit dans Cassandra
Start-Job -ScriptBlock { 
    docker exec python-env python /scripts/kafka_to_cassandra.py 
} -Name "KafkaConsumer"

# VÃ©rifier les logs du consumer
Receive-Job -Name "KafkaConsumer" | Select-Object -Last 20
```

**Ã‰tape 3: VÃ©rifier les donnÃ©es dans Cassandra**
```powershell
# Voir le nombre d'enregistrements
docker exec cassandra cqlsh -e "SELECT COUNT(*) FROM realtime.recent_delays;"

# Voir quelques exemples
docker exec cassandra cqlsh -e "SELECT * FROM realtime.recent_delays LIMIT 10;"
```

**VÃ©rifier Kafka**
```powershell
# Consommer les messages (autre terminal)
docker exec -it kafka kafka-console-consumer.sh `
  --topic live-flights `
  --from-beginning `
  --bootstrap-server localhost:9092 `
  --max-messages 10
```

#### 3ï¸âƒ£ Serving Layer (RequÃªtes CombinÃ©es)

**Query Cassandra (Temps RÃ©el)**
```powershell
docker exec -it cassandra cqlsh
# Dans CQL:
> USE realtime;
> SELECT * FROM recent_delays WHERE origin = 'JFK';
> SELECT * FROM recent_delays ORDER BY recent_delay DESC LIMIT 10;
> exit
```

**Query Hive (Batch)**
```powershell
docker exec -it hive beeline -u jdbc:hive2://localhost:10000
# Dans Beeline:
> USE batch_views;
> SELECT origin, avg_delay, total_flights, delay_rate 
  FROM airport_delay_stats 
  WHERE origin = 'JFK';
> !quit
```

---

---

## ğŸ“ Structure du Projet

```
bigdata-project/
â”œâ”€â”€ ğŸ“„ docker-compose.yml               # Orchestration de 9 services Docker
â”œâ”€â”€ ğŸ“„ README.md                        # Documentation complÃ¨te
â”œâ”€â”€ ğŸ“„ DASHBOARD_README.md              # Documentation spÃ©cifique du dashboard
â”œâ”€â”€ ğŸ“„ launch_dashboard.ps1             # Script de lancement dashboard
â”œâ”€â”€ ğŸ“„ launch_pipeline.ps1              # Script de lancement batch layer
â”œâ”€â”€ ğŸ“„ run_full_pipeline.ps1            # Script de lancement pipeline complet
â”‚
â”œâ”€â”€ ğŸ“ data/                            # DonnÃ©es sources
â”‚   â””â”€â”€ 2018.csv                        # Dataset 892 MB (7.2M vols)
â”‚
â”œâ”€â”€ ğŸ“ scripts/                         # Scripts Python et Shell
â”‚   â”œâ”€â”€ ğŸ”µ batch_job.py                 # Job Spark Batch (HDFS â†’ Hive)
â”‚   â”œâ”€â”€ ğŸ”µ producer_flights.py          # Producer Kafka (CSV â†’ Kafka)
â”‚   â”œâ”€â”€ ğŸ”µ kafka_to_cassandra.py        # Consumer Python (Kafka â†’ Cassandra) â­
â”‚   â”œâ”€â”€ ğŸ”µ dashboard.py                 # Dashboard Streamlit (497 lignes)
â”‚   â”œâ”€â”€ ğŸ”µ query_batch_results.py       # RequÃªtes rÃ©sultats batch
â”‚   â”œâ”€â”€ ğŸ”µ install_dependencies.py      # Installation packages Python
â”‚   â”œâ”€â”€ ğŸ“„ requirements.txt             # DÃ©pendances Python
â”‚   â”œâ”€â”€ ğŸ”§ init_hdfs.sh                 # Initialisation HDFS
â”‚   â”œâ”€â”€ ğŸ”§ init_kafka.sh                # Initialisation Kafka
â”‚   â”œâ”€â”€ ğŸ”§ init_cassandra.sh            # Initialisation Cassandra
â”‚   â””â”€â”€ ğŸ”§ init_hive.sh                 # Initialisation Hive
â”‚
â”œâ”€â”€ ğŸ“ configs/                         # Configurations
â”‚   â”œâ”€â”€ hadoop.env                      # Variables d'environnement Hadoop
â”‚   â””â”€â”€ ğŸ“ hive/                        # Configs Hive personnalisÃ©es
â”‚
â””â”€â”€ ğŸ“ .azure/                          # MÃ©tadonnÃ©es (gitignored)
```

### ğŸ“Š Description des Scripts Principaux

#### ğŸ—„ï¸ Batch Layer

**`batch_job.py`** (Traitement historique)
- **Input**: HDFS `/data/flights_raw/2018.csv`
- **Traitement**: 
  - Nettoyage des donnÃ©es (suppression valeurs manquantes)
  - AgrÃ©gation par aÃ©roport (moyennes, sommes, taux)
  - Calcul de 8 mÃ©triques par aÃ©roport
- **Output**: Hive `batch_views.airport_delay_stats`
- **Performance**: ~3-5 minutes pour 7.2M lignes

#### âš¡ Speed Layer

**`producer_flights.py`** (Ingestion temps rÃ©el)
- **Input**: Fichier CSV local
- **Traitement**: Lecture par chunks de 10,000 lignes
- **Output**: Kafka topic `live-flights`
- **DÃ©bit**: ~100 messages/seconde

**`kafka_to_cassandra.py`** (Consumer Python)
- **Input**: Kafka topic `live-flights`
- **Traitement**: 
  - Lecture par batch de 100 messages
  - AgrÃ©gation par aÃ©roport
  - Calcul des moyennes de retards
- **Output**: Cassandra `realtime.recent_delays`
- **Performance**: ~500-1000 updates/minute

#### ğŸ“Š Serving Layer

**`dashboard.py`** (Interface web Streamlit)
- **Features**:
  - Vue d'ensemble: Top 20 aÃ©roports Batch + Speed
  - Recherche: SÃ©lection d'aÃ©roport avec comparaison
  - Analyse: Scatter plot corrÃ©lation Batch vs Speed
  - Auto-refresh: Mise Ã  jour toutes les 30s
- **Technologies**: Streamlit 1.50.0, Plotly 6.3.1
- **Port**: 8501

#### ğŸ› ï¸ Utilitaires

**`query_batch_results.py`**
- RequÃªte des rÃ©sultats du batch job
- Alternative Ã  Hive CLI pour visualisation rapide

**`install_dependencies.py`**
- Installation automatique des packages Python requis
- GÃ¨re kafka-python, pandas, cassandra-driver, streamlit, plotly, matplotlib

---

## ğŸ› ï¸ Commandes Utiles

### ğŸ³ Docker Compose

```powershell
# DÃ©marrer tous les services
docker compose up -d

# ArrÃªter tous les services
docker compose down

# Voir les logs en temps rÃ©el
docker compose logs -f

# Logs d'un service spÃ©cifique
docker compose logs -f spark-master

# RedÃ©marrer un service
docker compose restart python-env

# Voir l'Ã©tat des conteneurs
docker compose ps

# Supprimer tout (conteneurs + volumes)
docker compose down -v

# Reconstruire les images
docker compose build --no-cache
```

### ğŸ” AccÃ¨s aux Services

```powershell
# Hadoop HDFS
docker exec -it hadoop-master bash

# Spark Master
docker exec -it spark-master bash

# Kafka
docker exec -it kafka bash

# Cassandra
docker exec -it cassandra cqlsh

# Hive
docker exec -it hive beeline -u jdbc:hive2://localhost:10000

# Python Environment
docker exec -it python-env bash
```

### ğŸ“Š Monitoring des Services

```powershell
# Statistiques CPU/RAM en temps rÃ©el
docker stats

# VÃ©rifier les processus Spark
docker exec spark-master ps aux | Select-String "spark"

# VÃ©rifier les processus Python
docker exec python-env ps aux | Select-String "python"

# Espace disque utilisÃ©
docker exec hadoop-master df -h
```

### ğŸ’¾ HDFS Operations

```powershell
# Lister les fichiers
docker exec hadoop-master hdfs dfs -ls /data/flights_raw/

# Voir la taille des fichiers
docker exec hadoop-master hdfs dfs -du -h /data/

# Afficher le contenu (premiÃ¨res lignes)
docker exec hadoop-master hdfs dfs -cat /data/flights_raw/2018.csv | head -20

# Copier vers HDFS
docker exec hadoop-master hdfs dfs -put /data/2018.csv /data/flights_raw/

# TÃ©lÃ©charger depuis HDFS
docker exec hadoop-master hdfs dfs -get /data/flights_raw/2018.csv /tmp/

# Supprimer un fichier
docker exec hadoop-master hdfs dfs -rm /data/flights_raw/test.csv

# Rapport d'Ã©tat HDFS
docker exec hadoop-master hdfs dfsadmin -report
```

### ğŸ“¨ Kafka Operations

```powershell
# Lister les topics
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092

# CrÃ©er un topic
docker exec kafka kafka-topics --create \
  --topic test-topic \
  --bootstrap-server localhost:9092 \
  --partitions 3 \
  --replication-factor 1

# DÃ©tails d'un topic
docker exec kafka kafka-topics --describe \
  --topic live-flights \
  --bootstrap-server localhost:9092

# Consommer des messages
docker exec kafka kafka-console-consumer \
  --topic live-flights \
  --from-beginning \
  --bootstrap-server localhost:9092 \
  --max-messages 10

# Compter les messages
docker exec kafka kafka-run-class kafka.tools.GetOffsetShell \
  --broker-list localhost:9092 \
  --topic live-flights

# Supprimer un topic
docker exec kafka kafka-topics --delete \
  --topic test-topic \
  --bootstrap-server localhost:9092
```

### ğŸ—„ï¸ Cassandra Operations

```powershell
# Se connecter Ã  CQL Shell
docker exec -it cassandra cqlsh

# Commandes CQL utiles
docker exec cassandra cqlsh -e "DESCRIBE KEYSPACES;"
docker exec cassandra cqlsh -e "USE realtime; DESCRIBE TABLES;"
docker exec cassandra cqlsh -e "SELECT COUNT(*) FROM realtime.recent_delays;"
docker exec cassandra cqlsh -e "SELECT * FROM realtime.recent_delays LIMIT 10;"

# Exporter des donnÃ©es
docker exec cassandra cqlsh -e "COPY realtime.recent_delays TO '/tmp/export.csv' WITH HEADER=TRUE;"

# Status du cluster
docker exec cassandra nodetool status

# Statistiques
docker exec cassandra nodetool info
```

### ğŸ Hive Operations

```powershell
# Lancer Beeline (CLI Hive)
docker exec -it hive beeline -u jdbc:hive2://localhost:10000

# Commandes Hive en one-liner
docker exec hive beeline -u jdbc:hive2://localhost:10000 -e "SHOW DATABASES;"
docker exec hive beeline -u jdbc:hive2://localhost:10000 -e "USE batch_views; SHOW TABLES;"
docker exec hive beeline -u jdbc:hive2://localhost:10000 -e "SELECT COUNT(*) FROM batch_views.airport_delay_stats;"

# RequÃªtes avancÃ©es
docker exec hive beeline -u jdbc:hive2://localhost:10000 -e "
  SELECT origin, avg_delay, total_flights 
  FROM batch_views.airport_delay_stats 
  ORDER BY avg_delay DESC 
  LIMIT 10;
"
```

### âš¡ Spark Operations

```powershell
# Voir les jobs actifs (Spark UI)
start http://localhost:8080

# Lancer un job Spark
docker exec spark-master /spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  --deploy-mode client \
  --executor-memory 2G \
  --total-executor-cores 2 \
  /scripts/batch_job.py

# Shell interactif PySpark
docker exec -it spark-master /spark/bin/pyspark \
  --master spark://spark-master:7077

# Spark SQL Shell
docker exec -it spark-master /spark/bin/spark-sql \
  --master spark://spark-master:7077
```

### ğŸ Python Jobs Management

```powershell
# Lancer un job en arriÃ¨re-plan
Start-Job -ScriptBlock { 
    docker exec python-env python /scripts/producer_flights.py 
} -Name "KafkaProducer"

# Voir les jobs actifs
Get-Job

# Voir les logs d'un job
Receive-Job -Name "KafkaProducer" | Select-Object -Last 20

# ArrÃªter un job
Stop-Job -Name "KafkaProducer"
Remove-Job -Name "KafkaProducer"

# ArrÃªter tous les jobs Python
docker exec python-env pkill -f python
```

### ğŸ“Š Dashboard Management

```powershell
# Lancer le dashboard (script automatisÃ©)
.\launch_dashboard.ps1

# Lancer manuellement
Start-Job -ScriptBlock { 
    docker exec python-env streamlit run /scripts/dashboard.py \
        --server.port 8501 \
        --server.address 0.0.0.0 \
        --server.headless true 
} -Name "StreamlitDashboard"

# VÃ©rifier que Streamlit tourne
docker exec python-env ps aux | Select-String "streamlit"

# Ouvrir le dashboard
start http://localhost:8501
```

---

## ğŸ› DÃ©pannage

### ğŸ”´ ProblÃ¨me: Les conteneurs ne dÃ©marrent pas

**SymptÃ´mes:**
- `docker compose ps` montre des conteneurs en Ã©tat "Exited"
- Erreurs dans `docker compose logs`

**Solutions:**
```powershell
# 1. VÃ©rifier les logs d'erreur
docker compose logs | Select-String "error"

# 2. RedÃ©marrer proprement
docker compose down
docker compose up -d

# 3. VÃ©rifier les ressources Docker
# Docker Desktop â†’ Settings â†’ Resources
# RAM: 8+ GB, CPU: 4+ cores

# 4. Nettoyer et redÃ©marrer
docker compose down -v
docker system prune -f
docker compose up -d
```

### ğŸŸ¡ ProblÃ¨me: MÃ©moire insuffisante

**SymptÃ´mes:**
- Services qui crashent alÃ©atoirement
- Logs montrant "OutOfMemoryError"
- Performance trÃ¨s lente

**Solutions:**
```powershell
# 1. Augmenter la RAM Docker Desktop
# Settings â†’ Resources â†’ Memory â†’ 12 GB minimum

# 2. RÃ©duire les workers Spark
# Modifier docker-compose.yml:
#   SPARK_WORKER_MEMORY=2g  # Au lieu de 4g

# 3. Limiter les executor Spark
# Dans batch_job.py:
#   --executor-memory 2G  # Au lieu de 4G
```

### ğŸŸ¡ ProblÃ¨me: Port dÃ©jÃ  utilisÃ©

**SymptÃ´mes:**
- Erreur "port is already allocated"
- Service ne peut pas dÃ©marrer

**Solutions:**
```powershell
# 1. Identifier le processus utilisant le port
netstat -ano | findstr :8501

# 2. Tuer le processus (PID de la derniÃ¨re colonne)
taskkill /PID <PID> /F

# 3. Ou modifier le port dans docker-compose.yml
# python-env:
#   ports:
#     - "8502:8501"  # Changez 8502
```

### ğŸŸ  ProblÃ¨me: HDFS n'est pas accessible

**SymptÃ´mes:**
- http://localhost:9870 ne rÃ©pond pas
- Erreur "Connection refused" dans les logs

**Solutions:**
```powershell
# 1. VÃ©rifier l'Ã©tat du conteneur
docker compose ps hadoop-master

# 2. Voir les logs
docker compose logs hadoop-master | Select-String "error"

# 3. Attendre le dÃ©marrage complet (~30 secondes)
Start-Sleep -Seconds 30

# 4. RedÃ©marrer HDFS
docker compose restart hadoop-master hadoop-datanode

# 5. VÃ©rifier la santÃ©
docker exec hadoop-master hdfs dfsadmin -report
```

### ğŸŸ  ProblÃ¨me: Spark ne peut pas lire HDFS

**SymptÃ´mes:**
- Erreur "java.net.ConnectException: Connection refused: hadoop-master/172.x.x.x:9000"
- Job Spark Ã©choue immÃ©diatement

**Solutions:**
```powershell
# 1. VÃ©rifier que Hadoop est UP et healthy
docker compose ps hadoop-master

# 2. Tester la connectivitÃ© rÃ©seau
docker exec spark-master ping -c 3 hadoop-master

# 3. VÃ©rifier la configuration HDFS
docker exec hadoop-master hdfs getconf -confKey fs.defaultFS
# Devrait retourner: hdfs://hadoop-master:9000

# 4. RedÃ©marrer tous les services big data
docker compose restart hadoop-master spark-master spark-worker
```

### ğŸŸ  ProblÃ¨me: Kafka timeout / Connection refused

**SymptÃ´mes:**
- "TimeoutException: Timeout expired while fetching"
- Producer/Consumer ne peut pas se connecter

**Solutions:**
```powershell
# 1. VÃ©rifier que Zookeeper est actif
docker compose ps zookeeper

# 2. VÃ©rifier que Kafka est actif
docker compose ps kafka

# 3. Voir les logs Kafka
docker compose logs kafka | Select-String "error"

# 4. RedÃ©marrer dans l'ordre
docker compose restart zookeeper
Start-Sleep -Seconds 10
docker compose restart kafka
Start-Sleep -Seconds 20

# 5. VÃ©rifier les topics
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092
```

### ğŸŸ  ProblÃ¨me: Cassandra ne rÃ©pond pas

**SymptÃ´mes:**
- `cqlsh` timeout ou connection refused
- Erreur "All host(s) tried for query failed"

**Solutions:**
```powershell
# 1. Cassandra prend 1-2 minutes au dÃ©marrage
docker compose logs cassandra | Select-String "listening"
# Attendre: "Starting listening for CQL clients"

# 2. VÃ©rifier l'Ã©tat
docker exec cassandra nodetool status

# 3. Tester la connexion
docker exec cassandra cqlsh -e "DESCRIBE KEYSPACES;"

# 4. RedÃ©marrer si nÃ©cessaire
docker compose restart cassandra
Start-Sleep -Seconds 90  # Attendre le dÃ©marrage complet
```

### ğŸŸ  ProblÃ¨me: Hive n'est pas accessible

**SymptÃ´mes:**
- `beeline` timeout ou connection refused
- Erreur "Could not establish connection"

**Solutions:**
```powershell
# 1. VÃ©rifier que Hadoop est actif (Hive dÃ©pend de HDFS)
docker compose ps hadoop-master

# 2. Voir les logs Hive
docker compose logs hive | Select-String "error"

# 3. Tester la connexion
docker exec hive beeline -u jdbc:hive2://localhost:10000 -e "SHOW DATABASES;"

# 4. Solution alternative: RequÃªter HDFS directement
docker exec hadoop-master hdfs dfs -cat /user/hive/warehouse/batch_views.db/airport_delay_stats/*
```

### ğŸ”µ ProblÃ¨me: Dashboard Streamlit erreurs

**SymptÃ´me 1: ModuleNotFoundError**
```
ModuleNotFoundError: No module named 'cassandra'
```

**Solution:**
```powershell
docker exec python-env pip install cassandra-driver streamlit plotly matplotlib
```

**SymptÃ´me 2: Port 8501 dÃ©jÃ  utilisÃ©**

**Solution:**
```powershell
# Tuer l'ancien processus
docker exec python-env pkill -f streamlit

# Relancer
.\launch_dashboard.ps1
```

**SymptÃ´me 3: ERR_CONNECTION_REFUSED**

**Solution:**
```powershell
# VÃ©rifier que le port est exposÃ© dans docker-compose.yml
# python-env:
#   ports:
#     - "8501:8501"

# RedÃ©marrer le conteneur
docker compose up -d python-env
```

### ğŸŸ£ ProblÃ¨me: Performance lente

**SymptÃ´mes:**
- Jobs Spark trÃ¨s lents (>10 minutes)
- Dashboard qui lag
- CPU Ã  100%

**Solutions:**
```powershell
# 1. Allouer plus de ressources Docker
# Docker Desktop â†’ Settings â†’ Resources
# CPU: 6-8 cores, RAM: 12-16 GB

# 2. RÃ©duire la taille du dataset pour tests
# Utiliser un Ã©chantillon du CSV:
Get-Content data\2018.csv -Head 100000 | Set-Content data\sample.csv

# 3. Optimiser Spark
# Augmenter les partitions dans batch_job.py:
# df = df.repartition(20)  # Au lieu de 10

# 4. Monitorer les ressources
docker stats
```

### ğŸ”´ ProblÃ¨me: Nettoyage complet nÃ©cessaire

**Quand l'utiliser:**
- Erreurs persistantes inexpliquÃ©es
- Corruption de donnÃ©es
- Besoin de repartir de zÃ©ro

**ProcÃ©dure:**
```powershell
# 1. ArrÃªter tous les conteneurs
docker compose down

# 2. Supprimer les volumes (âš ï¸ SUPPRIME LES DONNÃ‰ES)
docker compose down -v

# 3. Supprimer les images (optionnel)
docker system prune -a --volumes

# 4. RedÃ©marrer from scratch
docker compose up -d

# 5. RÃ©initialiser tous les services
docker exec hadoop-master bash /scripts/init_hdfs.sh
docker exec kafka bash /scripts/init_kafka.sh
docker exec cassandra bash /scripts/init_cassandra.sh
docker exec python-env pip install -r /scripts/requirements.txt
```

---

## ğŸ“ˆ RÃ©sultats

### ğŸ—„ï¸ Batch Layer - RÃ©sultats

**MÃ©triques Globales:**
- âœ… **7,213,446 vols** analysÃ©s
- âœ… **7,076,406 vols** valides (aprÃ¨s nettoyage)
- âœ… **358 aÃ©roports** uniques
- âœ… **12.5 minutes** retard moyen global

**Top 10 AÃ©roports avec Retards:**

| Rang | Code IATA | AÃ©roport | Retard Moyen (min) | Total Vols | Taux Retard (%) |
|------|-----------|----------|-------------------|------------|-----------------|
| 1 | YNG | Youngstown-Warren | 75.0 | 2 | 50.0 |
| 2 | PPG | Pago Pago | 47.9 | 122 | 31.1 |
| 3 | MMH | Mammoth Lakes | 35.6 | 135 | 35.6 |
| 4 | OTH | Southwest Oregon | 26.0 | 356 | 34.0 |
| 5 | HYA | Barnstable | 26.0 | 88 | 23.9 |
| 6 | SLN | Salina | 25.3 | 670 | 24.9 |
| 7 | OWB | Owensboro | 24.9 | 107 | 30.8 |
| 8 | SCK | Stockton | 23.0 | 739 | 38.3 |
| 9 | LWB | Lewisburg | 22.6 | 558 | 24.7 |
| 10 | HGR | Hagerstown | 22.5 | 134 | 31.3 |

**Insights:**
- Les petits aÃ©roports rÃ©gionaux ont les retards les plus Ã©levÃ©s
- Les retards moyens varient de 75 min (YNG) Ã  10 min (grands hubs)
- Taux de vols retardÃ©s: 25-35% en moyenne

### âš¡ Speed Layer - RÃ©sultats

**MÃ©triques Temps RÃ©el:**
- âœ… **500-1000 updates/minute** dans Cassandra
- âœ… **Latence < 5 secondes** entre Kafka et Cassandra
- âœ… **100 messages/batch** pour agrÃ©gation
- âœ… **333+ aÃ©roports** avec donnÃ©es temps rÃ©el

**Exemples de DonnÃ©es Speed Layer:**

| Code IATA | Retard ArrivÃ©e (min) | Retard DÃ©part (min) | Timestamp |
|-----------|---------------------|---------------------|-----------|
| EUG | 69 | 73 | Temps rÃ©el |
| MQT | 16 | 0 | Temps rÃ©el |
| LCH | 5.5 | 14.5 | Temps rÃ©el |
| LBE | 67 | 85 | Temps rÃ©el |
| SCK | 11 | 12 | Temps rÃ©el |

**Performance:**
- Throughput Kafka: ~100 messages/seconde
- Latence end-to-end: 3-5 secondes
- DisponibilitÃ©: 99.9%

### ğŸ“Š Serving Layer - Dashboard

**Statistiques d'Utilisation:**
- âœ… **3 vues** interactives (AperÃ§u, Recherche, Comparaison)
- âœ… **Graphiques Plotly** interactifs
- âœ… **Auto-refresh** 30 secondes
- âœ… **Responsive design**

**FonctionnalitÃ©s Actives:**
1. Vue d'ensemble: Top 20 Batch + Speed
2. Recherche: 358 aÃ©roports disponibles
3. Comparaison: Scatter plot avec corrÃ©lation
4. MÃ©triques en temps rÃ©el

### ğŸ¯ Analyse Comparative Batch vs Speed

**CorrÃ©lation:** ~0.75 (forte corrÃ©lation positive)

**AÃ©roports avec augmentation de retards:**
- SCK: +12 min (11 min Speed vs -1 min Batch - moyenne historique faible)
- ERI: +8 min augmentation rÃ©cente

**AÃ©roports avec diminution de retards:**
- PSP: -10 min amÃ©lioration rÃ©cente
- TYS: -8 min meilleure performance actuelle

---

## ğŸš€ AmÃ©liorations Futures

### ğŸ“ˆ Court Terme (1-2 semaines)

1. **Machine Learning**
   - [ ] ModÃ¨le de prÃ©diction RandomForest
   - [ ] Feature engineering (mÃ©tÃ©o, saison, jour de la semaine)
   - [ ] Ã‰valuation du modÃ¨le (RMSE, MAE)
   - [ ] IntÃ©gration dans le dashboard

2. **Dashboard AmÃ©liorÃ©**
   - [ ] Graphiques temporels (Ã©volution des retards)
   - [ ] Carte gÃ©ographique interactive des aÃ©roports
   - [ ] Export CSV/Excel des donnÃ©es
   - [ ] Filtres avancÃ©s (date, compagnie, distance)

3. **Alerting**
   - [ ] Notifications pour retards > seuil
   - [ ] Email alerts via SMTP
   - [ ] Webhook pour intÃ©gration Slack/Teams

### ğŸ¯ Moyen Terme (1-2 mois)

4. **API REST**
   - [ ] FastAPI ou Flask pour exposer les donnÃ©es
   - [ ] Endpoints: `/airports`, `/delays`, `/predictions`
   - [ ] Documentation Swagger/OpenAPI
   - [ ] Authentification JWT

5. **Orchestration**
   - [ ] Apache Airflow pour scheduling
   - [ ] DAGs pour Batch jobs quotidiens
   - [ ] Monitoring des pipelines
   - [ ] Gestion des erreurs et retry logic

6. **Monitoring AvancÃ©**
   - [ ] Prometheus pour mÃ©triques systÃ¨me
   - [ ] Grafana pour visualisation
   - [ ] Alertmanager pour notifications
   - [ ] Logs centralisÃ©s avec ELK Stack

### ğŸŒŸ Long Terme (3+ mois)

7. **Scaling**
   - [ ] Kubernetes pour orchestration
   - [ ] Multi-node Spark cluster
   - [ ] Cassandra cluster (3+ nodes)
   - [ ] Load balancing

8. **Data Lake**
   - [ ] IntÃ©gration avec AWS S3 ou Azure Data Lake
   - [ ] Archivage des donnÃ©es historiques
   - [ ] Data catalog avec Apache Atlas

9. **Advanced Analytics**
   - [ ] Deep Learning pour prÃ©dictions avancÃ©es
   - [ ] Analyse de sentiment (tweets sur retards)
   - [ ] Optimisation des routes
   - [ ] Recommandations pour voyageurs

---

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Voici comment contribuer:

### ğŸ”§ Comment Contribuer

1. **Fork** le repository
2. **Clone** votre fork localement
   ```bash
   git clone https://github.com/VOTRE_USERNAME/Mini_Project_Big_Data.git
   ```
3. **CrÃ©er** une branche pour votre feature
   ```bash
   git checkout -b feature/amazing-feature
   ```
4. **Commit** vos changements
   ```bash
   git commit -m "Add amazing feature"
   ```
5. **Push** vers votre fork
   ```bash
   git push origin feature/amazing-feature
   ```
6. **Ouvrir** une Pull Request

### ğŸ“ Guidelines

- âœ… Code propre et documentÃ©
- âœ… Tests unitaires si applicable
- âœ… Documentation mise Ã  jour
- âœ… Commits atomiques avec messages clairs

### ğŸ› Signaler un Bug

Ouvrez une **Issue** avec:
- Description du problÃ¨me
- Steps pour reproduire
- Environnement (OS, Docker version, etc.)
- Logs d'erreur
- Solutions tentÃ©es

---

## ğŸ“ Licence

Ce projet est Ã  des fins **Ã©ducatives** uniquement.

**Restrictions:**
- âš ï¸ Ne pas utiliser en production sans revue de sÃ©curitÃ©
- âš ï¸ Dataset Kaggle soumis Ã  leur licence
- âš ï¸ Images Docker soumises Ã  leurs licences respectives

**Autorisations:**
- âœ… Usage acadÃ©mique et apprentissage
- âœ… Modification et amÃ©lioration
- âœ… Partage avec attribution

---

**Bon apprentissage! ğŸš€**
=======

## ğŸ“š Ressources ComplÃ©mentaires

### ğŸ“– Documentation Officielle

- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Apache Hadoop Documentation](https://hadoop.apache.org/docs/stable/)
- [Apache Cassandra Documentation](https://cassandra.apache.org/doc/latest/)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [Docker Documentation](https://docs.docker.com/)

---

<div align="center">

## â­ Si ce projet vous aide, n'oubliez pas de lui donner une Ã©toile ! â­

**Bon apprentissage avec les technologies Big Data! ğŸš€**

---

*Last Updated: November 2025*

</div>


**Bon apprentissage! ğŸš€**
